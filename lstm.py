# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18B1xZ_cmrXX3R1ccIG0CaJIVgZD7xbjG

# **Loading Dataset**
"""

import pandas as pd

# Load the dataset
data_path = '/content/Truth_Seeker_Model_Dataset.csv'
dataset = pd.read_csv(data_path)

# Display the first few rows of the dataset
print(dataset.head(100))

a=dataset.shape[0]
b=dataset.shape[1]
print("The dataset has",a,"rows and",b,"columns.")

null_values = dataset.isnull().sum()
print("In each column number of null values :")
print(null_values)

if null_values.any():
    print("There are null values.")
else:
    print("There are no null values.")

true, false = dataset["target"].value_counts()

import matplotlib.pyplot as plt

label = ['true', 'false']
counts = [true, false]

plt.bar(label, counts, color=['blue', 'green'])
plt.title('Comparison of target Labels')
plt.xlabel('Dataset')
plt.ylabel('Count')
plt.show()

"""# **Pre Processing**"""

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

# Drop rows with any null values
dataset.dropna(subset=['statement', 'BinaryNumTarget'], inplace=True)

# Convert labels to integer type
dataset['BinaryNumTarget'] = dataset['BinaryNumTarget'].astype(int)

# Text preprocessing and sequence padding
tokenizer = Tokenizer()
tokenizer.fit_on_texts(dataset['statement'])
sequences = tokenizer.texts_to_sequences(dataset['statement'])
data = pad_sequences(sequences, maxlen=100)

# Labels
labels = np.array(dataset['BinaryNumTarget'])

# Splitting the dataset into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

m=X_train.shape[0]
n=X_test.shape[0]

print("Training set has:",m,"samples")
print("Test set has:", n ,"samples")

"""# **Model Building**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.metrics import Precision, Recall


# Model configuration
vocab_size = len(tokenizer.word_index) + 1

model = Sequential([
    Embedding(vocab_size, 100, input_length=100),
    LSTM(64, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])

model.summary()

"""# **Model Training**"""

# Train the model
history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), verbose=1)

"""# **Testing**"""

val_metrics = model.evaluate(X_val, y_val, verbose=0)
print(f'Validation - Loss: {val_metrics[0]}, Accuracy: {val_metrics[1]}, Precision: {val_metrics[2]}, Recall: {val_metrics[3]}')


test_metrics = model.evaluate(X_test, y_test, verbose=0)
print(f'Test - Loss: {test_metrics[0]}, Accuracy: {test_metrics[1]}, Precision: {test_metrics[2]}, Recall: {test_metrics[3]}')